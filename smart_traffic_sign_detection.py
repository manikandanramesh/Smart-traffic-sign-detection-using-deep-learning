# -*- coding: utf-8 -*-
"""smart traffic sign detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tjLPsac4s5NibY9nUpoHu79r4wg7pDvJ
"""

import os
os.environ['KAGGLE_CONFIG_DIR']='/content'
!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign

!unzip \*.zip && rm *.zip

#from PyQt5 import QtCore, QtGui, QtWidgets
from keras.models import Sequential, load_model
from keras.layers import Conv2D,MaxPool2D, Dense, Flatten, Dropout
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os

data=[]
labels=[]



classes=43
cur_path=os.getcwd()

print(cur_path)

classs={  1:"Speed limit (20km/h)",
           2:"Speed limit (30km/h)",
           3:"Speed limit (50km/h)",
           4:"Speed limit (60km/h)",
           5:"Speed limit (70km/h)",
           6:"Speed limit (80km/h)",
           7:"End of Speed limit (80km/h)",
           8:"Speed limit (100km/h)",
           9:"Speed limit (120km/h)",
           10:"No passing",
           11:"No passing veh over 3.5 tons",
           12:"Right-of-way at intersection",
           13:"Priority road",
           14:"Yield",
           15:"Stop",
           16:"No vehicles",
           17:"Veh > 3.5 tons prohibited",
           18:"No entry",
           19:"General caution",
           20:"Dangerous curve left",
           21:"Dangerous curve right",
           22:"Double curve",
           23:"Bumpy road",
           24:"Slippery road",
           25:"Road narrows on the right",
           26:"Road work",
           27:"Traffic signals",
           28:"Pedestrains",
           29:"Children crossing",
           30:"Bicycles crossing",
           31:"Beware of ice/snow",
           32:"Wild animals crossing",
           33:"End speed + passinng limits",
           34:"Turn right ahead",
           35:"Turn left ahead",
           36:"Ahead only",
           37:"Go straight or right",
           38:"Go straight or left",
           39:"Keep right",
           40:"Keep left",
           41:"Roundabout mandatory",
           42:"End of no passing",
           43:"End of no passing veh > 3.5 tons"}
#Retrieving the images and their labels
print("Obtaining Images & its Labels..............")
for i in range(classes):
    path=os.path.join('/content/Train/',str(i))
    images = os.listdir(path)
    for a in images:
        try:
            image = Image.open(path+'/'+a) 
            image = image.resize((30,30))
            image = np.array(image)
            data.append(image)
            labels.append(i)
            print("{0} Loaded".format(a))
        except:
            print("Error loading image")
    print("Loading..."+str((i/43*100)//1)+'%')
print("Datset Loaded")

#Converting lists into numpy arrays
data = np.array(data)
labels = np.array(labels)

print(data.shape, labels.shape)



#Spliting training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(data,labels, test_size=0.2,random_state=42)

print(X_train.shape, X_test.shape,y_train.shape, y_train.shape)

#converting the labels into one hot encoding
y_train = to_categorical(y_train,43)
y_test = to_categorical(y_test,43)


def trainingFunction():
    model =Sequential()
    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu',input_shape=X_train.shape[1:]))
    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))
    model.add(MaxPool2D(pool_size=(2,2)))
    model.add(Dropout(rate=0.25))
    model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))
    model.add(Conv2D(filters=64, kernel_size=(3,3),activation='relu'))
    model.add(MaxPool2D(pool_size=(2,2)))
    model.add(Dropout(rate=0.25))
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(rate=0.5))
    model.add(Dense(43, activation='softmax'))
    print("Intialized model")

    #Compilation of the model
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    history =  model.fit(X_train,y_train,batch_size = 32, epochs=30,validation_data=(X_test,y_test))
    model.save("my_model.h5")
       
    plt.figure(0)
    plt.plot(history.history['accuracy'],label='training accuracy')
    plt.plot(history.history['val_accuracy'],label='val_accuracy')
    plt.title('Accuracy')
    plt.xlabel('epochs')
    plt.ylabel('accuracy')
    plt.legend()
    plt.savefig('Accuracy.png')

    plt.figure(1)
    plt.plot(history.history['loss'],label='training loss')
    plt.plot(history.history['val_loss'],label='val_loss')
    plt.title('Loss')
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    plt.savefig('Loss.png')
trainingFunction()